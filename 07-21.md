# Lecture Notes: July 21th

## Idioms
The notion of doing things the, "correct way" came up during lecture. *Idioms* are recurring code fragments that does one thing. These fragments are simply the favored ways of coding an action based on the particular language and its design.

Idioms are a bit of a double-edged sword when first learning to code. On the one hand, they are set efficient ways of doing things that can simplify the problem solving process. On the other hand, they can be terse and conceptually obscure things.

While being able to write idiomatic code is part of fluency with a programming language, I would worry less about being able to code things the "correct way" and more about being able to code them in the first place.

You're welcome to use idioms if you are curious or would like a challenge or find them useful, but know that writing idiomatic Python--much like developing fluency in a second language--takes time.

## Computational Complexity
Austin mentioned during lecture the idea of *computational complexity*. Complexity is simply a way to quantify and classify the resource usage of problems, particularly time and memory.

Computational complexity is its own field of study, and could easily make for a course of its own. Most of it is well beyond the scope of this class. The most relevant idea to this class is the notion of limiting asymptotic behavior using *Big O* notation.

Big O notation describes how the run time or memory requirements of a program grow as a function of the size of the input. In particular, big O is an upper limit, describing the worst case for a program or algorithm.

Here are a couple of examples. Indexing a list is said to have *constant time*, `O(1)` as indexing element `n` will always take the same time independent of the size of the list. Interating over a list is said to have *linear time*, `O(n)` as the time that it takes to go over all the elements of a list is directly proportional to the number of the elements of the list. A for-loop nested in another for-loop is said to have *polynomial time*, `O(n^2)` as for every pass of the outer loop, you must execute the entirety of the inner loop.
